import os
import csv
import json
import shutil
import subprocess
import time
from datetime import datetime

# --- CONFIGURATION ---
DATASET_ROOT = "dataset_root"
GRAPH_DIR = os.path.join(DATASET_ROOT, "graphs")
LOG_FILE = os.path.join(DATASET_ROOT, "experiment_log.csv")

# Path to your Virtual Environment Python
# CHANGE THIS if your venv is named differently (e.g., .venv, my_env)
VENV_PYTHON = "./venv/bin/python3" 

# How many unique placements do you want to generate?
NUM_ITERATIONS = 1

def setup_database():
    """Creates the dataset folders and initializes CSV if missing."""
    if not os.path.exists(GRAPH_DIR):
        os.makedirs(GRAPH_DIR)
        print(f"ğŸ“ Created graph directory: {GRAPH_DIR}")

    if not os.path.exists(LOG_FILE):
        with open(LOG_FILE, "w", newline="") as f:
            writer = csv.writer(f)
            # Define the Master Schema
            header = [
                # 1. Identifiers
                "run_id", "placement_id", "design_name",
                # 2. Placement Context
                "aspect_ratio", "core_util", "density", "synth_strategy",
                # 3. CTS Knobs
                "cts_max_wire", "cts_buf_dist", "cts_cluster_size", "cts_cluster_dia",
                # 4. Metrics
                "skew_setup", "skew_hold", "power_total", "setup_slack", "wirelength"
            ]
            writer.writerow(header)
        print(f"ğŸ“„ Created log file: {LOG_FILE}")

def get_latest_run_tag():
    """Reads the tag from the file generated by Step 1."""
    try:
        with open("latest_run.txt", "r") as f:
            return f.readline().strip()
    except FileNotFoundError:
        return None

def log_data_to_csv(placement_id):
    """Merges config.json and dataset.json into the CSV."""
    run_dir = os.path.join("runs", placement_id)
    
    # A. Load Context
    config_path = os.path.join(run_dir, "config.json")
    if not os.path.exists(config_path):
        print("   âŒ Config file missing. Skipping log.")
        return
    with open(config_path, "r") as f:
        cfg = json.load(f)
    
    # B. Load Targets
    dataset_path = os.path.join(run_dir, "dataset.json")
    if not os.path.exists(dataset_path):
        print("   âŒ Dataset file missing. Skipping log.")
        return
    with open(dataset_path, "r") as f:
        experiments = json.load(f)

    # C. Write Rows
    with open(LOG_FILE, "a", newline="") as f:
        writer = csv.writer(f)
        for exp in experiments:
            knobs = exp.get("knobs", {})
            mets = exp.get("metrics", {})
            run_id = f"{placement_id}_{exp['id']}"

            row = [
                run_id, placement_id, cfg.get("DESIGN_NAME"),
                cfg.get("FP_ASPECT_RATIO"), cfg.get("FP_CORE_UTIL"),
                cfg.get("PL_TARGET_DENSITY"), cfg.get("SYNTH_STRATEGY"),
                knobs.get("CTS_CLK_MAX_WIRE_LENGTH"), knobs.get("CTS_DISTANCE_BETWEEN_BUFFERS"),
                knobs.get("CTS_SINK_CLUSTERING_SIZE"), knobs.get("CTS_SINK_CLUSTERING_MAX_DIAMETER"),
                mets.get("skew_setup"), mets.get("skew_hold"),
                mets.get("power_total"), mets.get("setup_slack"), mets.get("wirelength")
            ]
            writer.writerow(row)
    print(f"   âœ… Logged {len(experiments)} entries to CSV.")

def run_pipeline():
    setup_database()
    
    # Check if venv exists before starting
    if not os.path.exists(VENV_PYTHON):
        print(f"âŒ Error: Virtual Environment not found at {VENV_PYTHON}")
        print("   Please adjust 'VENV_PYTHON' variable at the top of the script.")
        return

    for i in range(NUM_ITERATIONS):
        print(f"\n========================================")
        print(f"ğŸ”„ GLOBAL ITERATION {i+1}/{NUM_ITERATIONS}")
        print(f"========================================")

        # --- STEP 1: GENERATE PLACEMENT ---
        print("ğŸ”¹ 1. Running Placement Generator...")
        subprocess.run(["python3", "scripts/1-gen-placement.py"], check=True)
        
        placement_id = get_latest_run_tag()
        if not placement_id:
            print("âŒ Critical Error: Could not get placement ID.")
            break
        print(f"   -> Generated ID: {placement_id}")

        # --- STEP 2: GENERATE SAIF (Activity) ---
        print("ğŸ”¹ 2. Generating SAIF Activity...")
        subprocess.run(["python3", "scripts/2-gen-saif.py", placement_id], check=True)

        # --- STEP 3: RAW GRAPH EXTRACTION (USES VENV) ---
        print("ğŸ”¹ 3. Building Raw Graph (Inside VENV)...")
        # Calls the venv python directly
        subprocess.run([VENV_PYTHON, "scripts/three_def_dict_to_raw_graph.py", placement_id], check=True)

        # --- STEP 4: GRAPH CLUSTERING (USES VENV) ---
        print("ğŸ”¹ 4. Clustering Graph (Inside VENV)...")
        # Calls the venv python directly
        subprocess.run([VENV_PYTHON, "scripts/4-graph_to_cluster.py", placement_id], check=True)
        
        # Move the final .pt file to the dataset folder
        src_pt = f"{placement_id}.pt" 
        dst_pt = os.path.join(GRAPH_DIR, f"{placement_id}.pt")
        
        if os.path.exists(src_pt):
            shutil.move(src_pt, dst_pt)
            print(f"   -> Saved Graph: {dst_pt}")
        else:
            print(f"   âš ï¸ Graph file {src_pt} not found in root. Check Step 4 output.")

        # --- STEP 5: CTS SWARM ---
        print("ğŸ”¹ 5. Running CTS Swarm...")
        subprocess.run(["python3", "scripts/5-run-cts.py", placement_id], check=True)

        # --- STEP 6: PARSE METRICS ---
        print("ğŸ”¹ 6. Parsing Metrics...")
        subprocess.run(["python3", "scripts/6-parse-cts-reports.py", placement_id], check=True)

        # --- STEP 7: LOG TO CSV ---
        print("ğŸ”¹ 7. Updating Database...")
        log_data_to_csv(placement_id)

if __name__ == "__main__":
    run_pipeline()